{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "06_Transfer_learning_in_tensorflow_scaling_up.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOA3eIFcoa2/hpjo5paxlR6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sandeepthetechie/mastering_the_art_of_tensorflow/blob/master/06_Transfer_learning_in_tensorflow_scaling_up.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEzlOxDPYnls",
        "outputId": "923f844e-d303-45ce-b42e-93465839a78d"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maORT4LDT5Lc"
      },
      "source": [
        "from helper_functions import create_tensorboard_callback, plot_loss_curves, unzip_data, compare_historys, walk_through_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uaoxqnbaugw"
      },
      "source": [
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/101_food_classes_10_percent.zip\n",
        "\n",
        "unzip_data(\"101_food_classes_10_percent.zip\")\n",
        "train_dir = \"101_food_classes_10_percent/train/\"\n",
        "test_dir = \"101_food_classes_10_percent/test/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkAWAaM5attI"
      },
      "source": [
        "walk_through_dir(\"101_food_classes_10_percent\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rds4OqFUatqS"
      },
      "source": [
        "# Setup data inputs\n",
        "# import tensorflow as tf\n",
        "IMG_SIZE = (224,224)\n",
        "train_data_all_10_percent = tf.keras.preprocessing.image_dataset_from_directory(train_dir, \n",
        "                                                                                label_mode = \"categorical\",\n",
        "                                                                                image_size = IMG_SIZE)\n",
        "\n",
        "test_data = tf.keras.preprocessing.image_dataset_from_directory(test_dir, \n",
        "                                                                label_mode = \"categorical\", \n",
        "                                                                image_size = IMG_SIZE, \n",
        "                                                                shuffle = False)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOn-XHlcatm-"
      },
      "source": [
        "# Create checkpoint callback\n",
        "checkpoint_path = \"101_food_classes_10_percent\"\n",
        "checkpoint_callback = tf.keras.preprocessing.callbacks.ModelCheckpoint(checkpoint_path, \n",
        "                                                                       save_weights_only= True, \n",
        "                                                                       monitor = \"val_accuracy\",\n",
        "                                                                       save_best_only = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsnqtFYqatj0"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "data_augmentation = Sequential([\n",
        "    preprocessing.RandomFlip(\"Horizontal\"), \n",
        "    preprocessing.RandomRotation(0.2),\n",
        "    preprocessing.RandomHeight(0.2), \n",
        "    preprocessing.RandomWidth(0.2),\n",
        "    preprocessing.RandomZoom(0.2)\n",
        "], name = \"data_augmentation\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0QGPTNzatgn"
      },
      "source": [
        "# Setup the base model and freeze its layers. \n",
        "base_model = tf.keras.applications.EfficientNetB0(include_top = False)\n",
        "base_model.trainable = False\n",
        "\n",
        "# Setup model architecture with trainable top layers.\n",
        "inputs = layers.Input(shape= (224,224,3), name = \"input_layer\")\n",
        "x = data_augmentation(inputs)\n",
        "x = base_model(x, training = False)\n",
        "x = layers.GlobalAveragePooling2D(name = \"global_avg_pool_layer\")(x)\n",
        "outputs = layers.Dense(len(train_data_all_10_percent.class_names), activation = \"softmax\", name = \"output_layer\")(x)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrmzBXLaatdg"
      },
      "source": [
        "# Compile \n",
        "model.compile(loss = \"categorical_crossentropy\",\n",
        "              optimizer = tf.keras.optimizers.Adam(), \n",
        "              metrics = [\"accuracy\"])\n",
        "\n",
        "# Fit \n",
        "history_all_classes_10_percent = model.fit(train_data_all_10_percent,\n",
        "                                           epochs = 5, \n",
        "                                           validation_data = test_data,\n",
        "                                           validation_steps = int(0.15 * len(test_data)),\n",
        "                                           callbacks = [checkpoint_callback])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDtHZ-ATatab"
      },
      "source": [
        "feature_extraction_results = model.evaluate(test_data)\n",
        "feature_extraction_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kgt1NzSCatXL"
      },
      "source": [
        "plot_loss_curves(feature_extraction_results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhjlSn_IatGn"
      },
      "source": [
        "# Fine turning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMPLjeyon2ZE"
      },
      "source": [
        "# Unfreeze all the layers in the base model\n",
        "base_model.trainable = True\n",
        "\n",
        "# Refreeze every layer except last 5. \n",
        "for layer in base_model.layers[:-5]:\n",
        "  layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmwwqjfyn2WR"
      },
      "source": [
        "model.compile(loss = \"categorical_crossentropy\",\n",
        "              optimizer = tf.keras.optimizers.Adam(lr = 0.0001), \n",
        "              metrics = [\"accuracy\"])\n",
        "\n",
        "for layer in model.layers:\n",
        "  print(layer.name, layer.trainable)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYimlBEIn2TQ"
      },
      "source": [
        "for layer_number, layer in enumerate(model.layers[2].layers):\n",
        "  print(layer_number, layer.name, layer.trainable)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DURuvwZyn2QH"
      },
      "source": [
        "fine_tune_epochs = 10\n",
        "\n",
        "history_all_classes_10_percent_fine_tune = model.fit(train_data_all_10_percent,\n",
        "                                                     epochs = fine_tune_epochs, \n",
        "                                                     validation_data = test_data, \n",
        "                                                     validation_steps = int(0.15 * len(test_data)),\n",
        "                                                     initial_epoch = history_all_classes_10_percent.epochs[-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXllWsmKn2NB"
      },
      "source": [
        "all_classes_10_percent_fine_tune_results = model.evaluate(test_data)\n",
        "all_classes_10_percent_fine_tune_results "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfySSOZqn2Jy"
      },
      "source": [
        "compare_historys(original_history = history_all_classes_10_percent,\n",
        "                 new_history = history_all_classes_10_percent_fine_tune,\n",
        "                 initial_epochs = 5\n",
        "                 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCLWNnTin2Gl"
      },
      "source": [
        "# Evaluate loaded model (the one we just downloaded on test data)\n",
        "results_downloaded_model = model.evaluate(test_data)\n",
        "results_downloaded_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIpgQqCLNWlE"
      },
      "source": [
        "# Save our fine-tuning model\n",
        "model.save(\"drive/MyDrive/tensorflow_course/101_food_classes_10_percent_saved_big_dog_model\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26l8GTBKNWxJ"
      },
      "source": [
        "# Load an evaluate saved model\n",
        "loaded_model = tf.keras.models.load_model(\"drive/MyDrive/tensorflow_course/101_food_classes_10_percent_saved_big_dog_model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "os2v3D7dNXHe"
      },
      "source": [
        "# Evaluate loaded model (the one we just downloaded on test data)\n",
        "results_downloaded_model = model.evaluate(test_data)\n",
        "results_downloaded_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctPgEnpSNXKT"
      },
      "source": [
        "# Make predictions with model\n",
        "preds_probs = model.predict(test_data, verbose=1) # set verbosity to see how long is left"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uv6j5vZJNXOZ"
      },
      "source": [
        "len(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5lASsV0NXR-"
      },
      "source": [
        "len(pred_probs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTp59TLhNXU9"
      },
      "source": [
        "pred_probs.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5aqzk8INXXt"
      },
      "source": [
        "pred_probs[0], len(pred_probs[0]), sum(pred_probs[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBMp-LBWNXbN"
      },
      "source": [
        "pred_classes = pred_probs.argmax(axis = 1)\n",
        "\n",
        "pred_classes[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxzxccJkXnAa"
      },
      "source": [
        "len(pred_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fM946lohXnfQ"
      },
      "source": [
        "y_labels = []\n",
        "\n",
        "for images, labels in test_data.unbatch():\n",
        "  y_labels.append(labels.numpy().argmax())\n",
        "\n",
        "y_labels[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jhs6Cg1DXnlA"
      },
      "source": [
        "results_downloaded_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFbFk6a_Xnof"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "sklearn_accuracy = accuracy_score(y_true = y_labels, \n",
        "                                  y_pred = pred_classes)\n",
        "sklearn_accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9u-7jHlXnsb"
      },
      "source": [
        "import numpy as np\n",
        "np.isclose(results_downloaded_model[1], sklearn_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3sqlelzXnyR"
      },
      "source": [
        "# Confusion matrix "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKwFpNbqyXs0"
      },
      "source": [
        "from helper_functions import make_confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlVt4WwMyXpn"
      },
      "source": [
        "class_names = test_data.class_names\n",
        "class_names "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dH4X75MzyXeC"
      },
      "source": [
        "make_confusion_matrix(y_true = y_labels,\n",
        "                      y_pred = pred_classes,\n",
        "                      classes = class_names\n",
        "                      figsize = (100,100),\n",
        "                      test_size = 20,\n",
        "                      save_fig = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tIsNLuDyXXN"
      },
      "source": [
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# We need to make some changes to our make_confusion_matrix function to ensure the x-labels print vertically\n",
        "def make_confusion_matrix(y_true, y_pred, classes=None, figsize=(10, 10), text_size=15, norm=False, savefig=False): \n",
        "  \"\"\"Makes a labelled confusion matrix comparing predictions and ground truth labels.\n",
        "\n",
        "  If classes is passed, confusion matrix will be labelled, if not, integer class values\n",
        "  will be used.\n",
        "\n",
        "  Args:\n",
        "    y_true: Array of truth labels (must be same shape as y_pred).\n",
        "    y_pred: Array of predicted labels (must be same shape as y_true).\n",
        "    classes: Array of class labels (e.g. string form). If `None`, integer labels are used.\n",
        "    figsize: Size of output figure (default=(10, 10)).\n",
        "    text_size: Size of output figure text (default=15).\n",
        "    norm: normalize values or not (default=False).\n",
        "    savefig: save confusion matrix to file (default=False).\n",
        "  \n",
        "  Returns:\n",
        "    A labelled confusion matrix plot comparing y_true and y_pred.\n",
        "\n",
        "  Example usage:\n",
        "    make_confusion_matrix(y_true=test_labels, # ground truth test labels\n",
        "                          y_pred=y_preds, # predicted labels\n",
        "                          classes=class_names, # array of class label names\n",
        "                          figsize=(15, 15),\n",
        "                          text_size=10)\n",
        "  \"\"\"  \n",
        "  # Create the confustion matrix\n",
        "  cm = confusion_matrix(y_true, y_pred)\n",
        "  cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis] # normalize it\n",
        "  n_classes = cm.shape[0] # find the number of classes we're dealing with\n",
        "\n",
        "  # Plot the figure and make it pretty\n",
        "  fig, ax = plt.subplots(figsize=figsize)\n",
        "  cax = ax.matshow(cm, cmap=plt.cm.Blues) # colors will represent how 'correct' a class is, darker == better\n",
        "  fig.colorbar(cax)\n",
        "\n",
        "  # Are there a list of classes?\n",
        "  if classes:\n",
        "    labels = classes\n",
        "  else:\n",
        "    labels = np.arange(cm.shape[0])\n",
        "  \n",
        "  # Label the axes\n",
        "  ax.set(title=\"Confusion Matrix\",\n",
        "         xlabel=\"Predicted label\",\n",
        "         ylabel=\"True label\",\n",
        "         xticks=np.arange(n_classes), # create enough axis slots for each class\n",
        "         yticks=np.arange(n_classes), \n",
        "         xticklabels=labels, # axes will labeled with class names (if they exist) or ints\n",
        "         yticklabels=labels)\n",
        "  \n",
        "  # Make x-axis labels appear on bottom\n",
        "  ax.xaxis.set_label_position(\"bottom\")\n",
        "  ax.xaxis.tick_bottom()\n",
        "\n",
        "  ### Changed (plot x-labels vertically) ###\n",
        "  plt.xticks(rotation=70, fontsize=text_size)\n",
        "  plt.yticks(fontsize=text_size)\n",
        "\n",
        "  # Set the threshold for different colors\n",
        "  threshold = (cm.max() + cm.min()) / 2.\n",
        "\n",
        "  # Plot the text on each cell\n",
        "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    if norm:\n",
        "      plt.text(j, i, f\"{cm[i, j]} ({cm_norm[i, j]*100:.1f}%)\",\n",
        "              horizontalalignment=\"center\",\n",
        "              color=\"white\" if cm[i, j] > threshold else \"black\",\n",
        "              size=text_size)\n",
        "    else:\n",
        "      plt.text(j, i, f\"{cm[i, j]}\",\n",
        "              horizontalalignment=\"center\",\n",
        "              color=\"white\" if cm[i, j] > threshold else \"black\",\n",
        "              size=text_size)\n",
        "\n",
        "  # Save the figure to the current working directory\n",
        "  if savefig:\n",
        "    fig.savefig(\"confusion_matrix.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNVhuJ5i1SLR"
      },
      "source": [
        "make_confusion_matrix(y_true=y_labels,\n",
        "                      y_pred=pred_classes,\n",
        "                      classes=class_names,\n",
        "                      figsize=(100, 100),\n",
        "                      text_size=20,\n",
        "                      savefig=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYgkTD3p1SEz"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_true=y_labels,\n",
        "                            y_pred=pred_classes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGtewfnV1R6p"
      },
      "source": [
        "# Get a dictionary of the classification report\n",
        "classification_report_dict = classification_report(y_labels, pred_classes, output_dict=True)\n",
        "classification_report_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XB2ZmJiM1R3y"
      },
      "source": [
        "class_names[98]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtZpAeQf1Rfi"
      },
      "source": [
        "# Create empty dictionary\n",
        "class_f1_scores = {}\n",
        "# Loop through classification report dictionary items\n",
        "for k, v in classification_report_dict.items():\n",
        "  if k == \"accuracy\": # stop once we get to accuracy key\n",
        "    break\n",
        "  else:\n",
        "    # Add class names and f1-scores to new dictionary\n",
        "    class_f1_scores[class_names[int(k)]] = v[\"f1-score\"]\n",
        "class_f1_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tst4EW_r25tF"
      },
      "source": [
        "# Trun f1-scores into dataframe for visualization\n",
        "import pandas as pd\n",
        "f1_scores = pd.DataFrame({\"class_names\": list(class_f1_scores.keys()),\n",
        "                          \"f1-score\": list(class_f1_scores.values())}).sort_values(\"f1-score\", ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u73vI4N_25qN"
      },
      "source": [
        "# What does our dataframe look like?\n",
        "f1_scores[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjK0XX5M25lW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4E_2DCqyXUm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}